{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEsHWyFJX6xD"
   },
   "source": [
    "# Преобразование обучающих изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gzuv2run9Yxa",
    "outputId": "5bb9661e-9ed7-4d37-af07-9c93bc0f55a4"
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "# !pip install fiona\n",
    "import fiona\n",
    "# !pip install segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_folder: str, transform = None):\n",
    "        self.class_ids = {\"vessel\": 1}\n",
    "\n",
    "        self.data_folder = data_folder\n",
    "        self.transform = transform\n",
    "        self._image_files = glob.glob(f\"{data_folder}/all_sorted_data/*i.png\")\n",
    "#         print(self._image_files)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_image(path: str) -> np.ndarray:\n",
    "        image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = np.array(image / 255, dtype=np.float32)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        # Достаём имя файла по индексу\n",
    "        image_path = self._image_files[idx]\n",
    "#         print(image_path)\n",
    "\n",
    "        # Получаем соответствующий файл разметки\n",
    "        mask_path = image_path.replace(\"i\", \"m\")\n",
    "#         print(mask_path)\n",
    "        if os.path.isfile(mask_path):\n",
    "            image = self.read_image(image_path)\n",
    "            mask = self.read_image(mask_path)\n",
    "\n",
    "            sample = {'image': image,\n",
    "                      'mask': mask}\n",
    "\n",
    "            if self.transform is not None:\n",
    "                sample = self.transform(**sample)\n",
    "\n",
    "            return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._image_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7URcg7KlMqbV"
   },
   "outputs": [],
   "source": [
    "# Задаем преобразование изображений\n",
    "size = 512\n",
    "def strong_aug(p=0.5):\n",
    "    return Compose([\n",
    "        albu.LongestMaxSize(size, interpolation=cv2.INTER_CUBIC, always_apply=True),\n",
    "        albu.PadIfNeeded(size, size, always_apply=True),\n",
    "# #         albu.RandomCrop(height=512, width=512, always_apply=True),\n",
    "# #         ToTensorV2(transpose_mask=True),\n",
    "        RandomRotate90(),\n",
    "        Flip(),\n",
    "# #         Transpose(),\n",
    "        OneOf([\n",
    "#             IAAAdditiveGaussianNoise(),\n",
    "            GaussNoise(),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            MotionBlur(p=0.2),\n",
    "            MedianBlur(blur_limit=3, p=0.1),\n",
    "            Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        OneOf([\n",
    "            OpticalDistortion(p=0.3),\n",
    "            GridDistortion(p=0.1),\n",
    "#             IAAPiecewiseAffine(p=0.3),\n",
    "        ], p=0.2),\n",
    "        OneOf([\n",
    "            CLAHE(clip_limit=2),\n",
    "            IAASharpen(),\n",
    "            IAAEmboss(),\n",
    "            RandomBrightnessContrast(),\n",
    "        ], p=0.3),\n",
    "        HueSaturationValue(p=0.3),\n",
    "    ], p=p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5vqgjSAyMwT4"
   },
   "outputs": [],
   "source": [
    "# Инициализируем датасет\n",
    "dataset = EyeDataset(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 510/510 [03:09<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in tqdm(dataset):\n",
    "    if i != None:\n",
    "        mask = i['mask']\n",
    "        mask = mask[:,:,1]\n",
    "        mask *= 255\n",
    "        mask = mask.astype(np.uint8)\n",
    "#         mask = cv2.normalize(mask, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "        image = i['image']\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "#         print(image)\n",
    "\n",
    "    \n",
    "        augmentation = strong_aug(p=0.9)\n",
    "        data = {\"image\": image, \"mask\": mask}\n",
    "        for i in range(3):\n",
    "\n",
    "            augmented = augmentation(**data)\n",
    "            imageA, maskA = augmented[\"image\"], augmented[\"mask\"]\n",
    "            result_m = Image.fromarray((maskA).astype(np.uint8))\n",
    "            result_i = Image.fromarray((imageA).astype(np.uint8))        \n",
    "            result_i.save(f'data/images512/{count}.png')\n",
    "            result_m.save(f'data/masks512/{count}.png')\n",
    "\n",
    "            count += 1\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
